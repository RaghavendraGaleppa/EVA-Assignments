{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 7B",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvj1KfVGw68m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo24NR7Zwsu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPool2D, DepthwiseConv2D,\n",
        "        Input,Flatten,Activation, concatenate, BatchNormalization, GlobalAvgPool2D)\n",
        "from tensorflow.keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtnkdAfm5pKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modify_concatenate(layers):\n",
        "    \"\"\"\n",
        "        - This function will concatenate different layers with different height and width\n",
        "        - For example, there are two layers of shape (32,32,40)  and (16,16,20), it is not possible to concatenate\n",
        "            these layers as they are. They bigger layer(the one with shape (32,32,40)) needs to be modified to \n",
        "            shape (16,16,x) to concatenate it with the smaller layer. This modification is done by tf.nn.space_to_depth.\n",
        "        - This will modify the the layers to match the height and width of the smallest sized layer\n",
        "    \"\"\"\n",
        "\n",
        "    layer_specs = [] # Hold the height and width of each layer along with the layer\n",
        "    min_height = 999999\n",
        "    min_width = 999999\n",
        "    for layer in layers:\n",
        "        layer_shape = K.int_shape(layer)\n",
        "        height = layer_shape[-3] \n",
        "        width = layer_shape[-2]\n",
        "\n",
        "        # Check if the height and width of this layer is the smallest out of all layers and \n",
        "        # assign it to min_height and min_weight\n",
        "        min_height = min(min_height, height)\n",
        "        min_width = min(min_width, width)\n",
        "        \n",
        "        layer_specs.append([layer, height, width])\n",
        "\n",
        "    # Now its time to modify the layers to match the size of the smallest layer\n",
        "    modified_layers = [] # This list will hold modified layers\n",
        "    for layer, height, width in layer_specs:\n",
        "        if(int(height/min_height) > 1):\n",
        "            # Modify the layer \n",
        "            layer = tf.nn.space_to_depth(layer,block_size=int(height/min_height))\n",
        "            modified_layers.append(layer)\n",
        "        else:\n",
        "            # It implies that the layer is the shortest\n",
        "            modified_layers.append(layer)\n",
        "    \n",
        "    # Now concatenate the modified layers\n",
        "    layers_concatenated = concatenate(modified_layers)\n",
        "    return layers_concatenated\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8rbRJA5xTdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Building Block 1\n",
        "\"\"\"\n",
        "inputs = Input((32,32,3))\n",
        "\n",
        "# Layer 1\n",
        "layer_1 = DepthwiseConv2D((5,5),padding='same',depth_multiplier=8)(inputs)\n",
        "layer_1 = BatchNormalization()(layer_1)\n",
        "layer_1 = Activation('relu')(layer_1)\n",
        "\n",
        "# Layer 2\n",
        "layer_2 = Conv2D(32,(5,5),padding='same',strides=1)(layer_1)\n",
        "layer_2 = BatchNormalization()(layer_2)\n",
        "layer_2 =   Activation('relu')(layer_2)\n",
        "\n",
        "# Layer 3\n",
        "layer_3 = Conv2D(32,(5,5),padding='same',strides=1)(layer_2)\n",
        "layer_3 = BatchNormalization()(layer_3)\n",
        "layer_3 =   Activation('relu')(layer_3)\n",
        "\n",
        "# Layer 4\n",
        "layer_4 = DepthwiseConv2D((5,5), padding='same',depth_multiplier=2)(concatenate([layer_1,layer_3]))\n",
        "layer_4 = BatchNormalization()(layer_4)\n",
        "layer_4 =   Activation('relu')(layer_4)\n",
        "\n",
        "# Layer 5\n",
        "layer_5 = MaxPool2D((2,2))(concatenate([layer_4, layer_1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIPykFp15w5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Building Block 2\n",
        "\"\"\"\n",
        "\n",
        "# Layer 6\n",
        "layer_6 = DepthwiseConv2D((3,3), padding='same',depth_multiplier=2)(layer_5)\n",
        "layer_6 = BatchNormalization()(layer_6)\n",
        "layer_6 =   Activation('relu')(layer_6)\n",
        "\n",
        "# Layer 7: Concatenate layer_1, layer_4, layer_6\n",
        "inputs_layer_7 = modify_concatenate([layer_1,layer_4,layer_6])\n",
        "layer_7 = Conv2D(32, (5,5),padding='same',strides=1)(inputs_layer_7)\n",
        "layer_7 = BatchNormalization()(layer_7)\n",
        "layer_7 =   Activation('relu')(layer_7)\n",
        "\n",
        "# Layer 8: Concatenate layer_3, layer_4, layer_6, layer_7\n",
        "inputs_layer_8 = modify_concatenate([layer_3, layer_4, layer_6, layer_7])\n",
        "layer_8 = DepthwiseConv2D((3,3), padding='same', depth_multiplier=2)(inputs_layer_8)\n",
        "layer_8 = BatchNormalization()(layer_8)\n",
        "layer_8 =   Activation('relu')(layer_8)\n",
        "\n",
        "# Layer 9: 6 layers are being Concatenated to form the input of layer_9\n",
        "# Concatenate layer_8, layer_7, layer_6, layer_4, layer_3, layer_1\n",
        "inputs_layer_9 = modify_concatenate([layer_8,layer_6,layer_1, layer_4, layer_7,layer_3]) \n",
        "layer_9 = DepthwiseConv2D((5,5), padding='same',depth_multiplier=2)(inputs_layer_9)\n",
        "layer_9 = BatchNormalization()(layer_9)\n",
        "layer_9 =   Activation('relu')(layer_9)\n",
        "\n",
        "# Layer 10: 5 layers to concatenate\n",
        "# Concatenate layer_9, layer_8, layer_6, layer_4, layer_1\n",
        "inputs_layer_10 = modify_concatenate([layer_9, layer_8, layer_6, layer_4, layer_1])\n",
        "layer_10 = MaxPool2D((2,2))(inputs_layer_10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BReqqqTB7gB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Building Block 3\n",
        "\"\"\"\n",
        "\n",
        "# Layer 11: 2 layers to concatenate\n",
        "# Concatenate layer_10, layer_7\n",
        "inputs_layer_11 = modify_concatenate([layer_10,layer_7])\n",
        "layer_11 = Conv2D(32,(5,5),padding='same',strides=1)(inputs_layer_11)\n",
        "layer_11 = BatchNormalization()(layer_11)\n",
        "layer_11 =   Activation('relu')(layer_11)\n",
        "\n",
        "# Layer 12: 4 layers to concatenate\n",
        "# Concatenate layer_11, layer_8, layer_2, layer_4\n",
        "inputs_layer_12 = modify_concatenate([layer_11, layer_8, layer_2, layer_4])\n",
        "layer_12 = DepthwiseConv2D((5,5), padding='same', depth_multiplier=2)(inputs_layer_12)\n",
        "layer_12 = BatchNormalization()(layer_12)\n",
        "layer_12 =   Activation('relu')(layer_12)\n",
        "\n",
        "# Layer 13: 5 layers to concatenate\n",
        "# Concatenate layer_12, layer_11, layer_3, layer_2, layer_6\n",
        "inputs_layer_13 = modify_concatenate([layer_12, layer_11, layer_3, layer_2, layer_6])\n",
        "layer_13 = Conv2D(32, (3,3), padding='same', strides=1)(inputs_layer_13)\n",
        "layer_13 = BatchNormalization()(layer_13)\n",
        "layer_13 =   Activation('relu')(layer_13)\n",
        "\n",
        "# Layer 14: 7 layers to concatenate\n",
        "# Concatenate layer_13, layer_12, layer_8, layer_3, layer_6, layer_4,  layer_1\n",
        "inputs_layer_14 = modify_concatenate([layer_13, layer_12, layer_8, layer_3, layer_6, layer_4, layer_1])\n",
        "layer_14 = DepthwiseConv2D((5,5), padding='same', depth_multiplier=2)(inputs_layer_14)\n",
        "layer_14 = BatchNormalization()(layer_14)\n",
        "\n",
        "# Layer 15: 4 layers to concatenate\n",
        "# Concatenate layer 14, layer_12, layer_4, layer_8\n",
        "inputs_layer_15 = modify_concatenate([layer_14, layer_12, layer_4, layer_8])\n",
        "# Create a transition layer from X input kernels to 10 classes\n",
        "layer_15 = Conv2D(10,(1,1),padding='same',strides=1)(inputs_layer_15)\n",
        "layer_15 = BatchNormalization()(layer_15)\n",
        "layer_15 = Activation('relu')(layer_15)\n",
        "\n",
        "# Add a global averge pool layer\n",
        "gap_layer_15 = GlobalAvgPool2D()(layer_15)\n",
        "layer_15 =   Activation('softmax')(gap_layer_15)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy8rZ0QCxak_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=inputs, outputs=layer_15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmcPsmkV0kfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f39c459-83eb-4d4d-badf-d178ad655dbf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_14 (DepthwiseC (None, 32, 32, 24)   624         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 24)   96          depthwise_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 24)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 32)   19232       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 32)   25632       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 56)   0           activation[0][0]                 \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_15 (DepthwiseC (None, 32, 32, 112)  2912        concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 112)  448         depthwise_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 112)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 136)  0           activation_3[0][0]               \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 136)  0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_16 (DepthwiseC (None, 16, 16, 272)  2720        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 272)  1088        depthwise_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 272)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_11 (Te [(None, 16, 16, 96)] 0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_12 (Te [(None, 16, 16, 448) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 816)  0           tf_op_layer_SpaceToDepth_11[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_12[0][0]\n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   652832      concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_13 (Te [(None, 16, 16, 128) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_14 (Te [(None, 16, 16, 448) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 880)  0           tf_op_layer_SpaceToDepth_13[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_14[0][0]\n",
            "                                                                 activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_17 (DepthwiseC (None, 16, 16, 1760) 17600       concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 1760) 7040        depthwise_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 1760) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_15 (Te [(None, 16, 16, 96)] 0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_16 (Te [(None, 16, 16, 448) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_17 (Te [(None, 16, 16, 128) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 2736) 0           activation_6[0][0]               \n",
            "                                                                 activation_4[0][0]               \n",
            "                                                                 tf_op_layer_SpaceToDepth_15[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_16[0][0]\n",
            "                                                                 activation_5[0][0]               \n",
            "                                                                 tf_op_layer_SpaceToDepth_17[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_18 (DepthwiseC (None, 16, 16, 5472) 142272      concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 5472) 21888       depthwise_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 5472) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_18 (Te [(None, 16, 16, 448) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_19 (Te [(None, 16, 16, 96)] 0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 8048) 0           activation_7[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "                                                                 activation_4[0][0]               \n",
            "                                                                 tf_op_layer_SpaceToDepth_18[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_19[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 8048)   0           concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_48 (Te [(None, 8, 8, 128)]  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 8176)   0           max_pooling2d_6[0][0]            \n",
            "                                                                 tf_op_layer_SpaceToDepth_48[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 32)     6540832     concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 32)     128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 32)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_49 (Te [(None, 8, 8, 7040)] 0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_50 (Te [(None, 8, 8, 512)]  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_51 (Te [(None, 8, 8, 1792)] 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 9376)   0           activation_16[0][0]              \n",
            "                                                                 tf_op_layer_SpaceToDepth_49[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_50[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_51[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_23 (DepthwiseC (None, 8, 8, 18752)  487552      concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 18752)  75008       depthwise_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 18752)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_52 (Te [(None, 8, 8, 512)]  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_53 (Te [(None, 8, 8, 512)]  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_54 (Te [(None, 8, 8, 1088)] 0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 20896)  0           activation_17[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "                                                                 tf_op_layer_SpaceToDepth_52[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_53[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_54[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 32)     6018080     concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 32)     128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 32)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_55 (Te [(None, 8, 8, 7040)] 0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_56 (Te [(None, 8, 8, 512)]  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_57 (Te [(None, 8, 8, 1088)] 0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_58 (Te [(None, 8, 8, 1792)] 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_59 (Te [(None, 8, 8, 384)]  0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 29600)  0           activation_18[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 tf_op_layer_SpaceToDepth_55[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_56[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_57[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_58[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_59[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_24 (DepthwiseC (None, 8, 8, 59200)  1539200     concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 59200)  236800      depthwise_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_60 (Te [(None, 8, 8, 1792)] 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SpaceToDepth_61 (Te [(None, 8, 8, 7040)] 0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 86784)  0           batch_normalization_20[0][0]     \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 tf_op_layer_SpaceToDepth_60[0][0]\n",
            "                                                                 tf_op_layer_SpaceToDepth_61[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 10)     867850      concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 10)     40          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 10)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 10)           0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 10)           0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 16,660,386\n",
            "Trainable params: 16,488,862\n",
            "Non-trainable params: 171,524\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8YDC02W0oCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}