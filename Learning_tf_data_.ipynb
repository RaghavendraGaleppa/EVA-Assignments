{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning tf.data .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaghavendraGaleppa/EVA-Assignments/blob/master/Learning_tf_data_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOq1jX5trfSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8GJmfKUr9DI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq_6_Klx2Njq",
        "colab_type": "text"
      },
      "source": [
        "# Converting numpy data to TFRecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgZdUqHf26Xm",
        "colab_type": "text"
      },
      "source": [
        "### First convert the numpy data in tf.data.Dataset Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkLw70UX3BUE",
        "colab_type": "code",
        "outputId": "759e1264-6467-48fa-b504-67034cf5b398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test = tf.keras.datasets.cifar10.load_data()\n",
        "print(f\"Shape of image data:{X_train[0].shape}, Shape of labels data:{X_train[1].shape}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of image data:(50000, 32, 32, 3), Shape of labels data:(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqcK8deO6lUB",
        "colab_type": "code",
        "outputId": "1c2099bb-7ad1-4099-a2c0-f6c1693365ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "\"\"\"\n",
        "Using tf.data.Dataset.from_tensor_slices is the method convert numpy arrays to tf.data.Dataset type\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "example = tf.data.Dataset.from_tensor_slices([0,1,43,123,31,45])\n",
        "print(example)\n",
        "\n",
        "example = tf.data.Dataset.from_tensor_slices(np.array([0,2,3,4,13,123,44,123,34]))\n",
        "print(example)\n",
        "\n",
        "example = tf.data.Dataset.from_tensor_slices(np.array([0.1,23.01]))\n",
        "print(example)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: (), types: tf.int32>\n",
            "<TensorSliceDataset shapes: (), types: tf.int64>\n",
            "<TensorSliceDataset shapes: (), types: tf.float64>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmvKfxrJ7_pv",
        "colab_type": "code",
        "outputId": "d14ac571-ff7f-45a3-abf2-066f5c591484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "\"\"\"\n",
        "    - You can loop over the tf.data.Dataset type as if it were an iterator.\n",
        "    - Each Element of the tf.data.Dataset type is a tf.Tensor which is similar to numpy\n",
        "    arrays but is a made for tensorflow and also supports GPU Operations.\n",
        "    - Each of the tf.Tensor say for example some_tensor can be converted to numpy arrays by calling\n",
        "    some_tensor.numpy() function\n",
        "\"\"\"\n",
        "\n",
        "# Here each 'e' is a tf.Tensor type \n",
        "# You can add, subtract, multiply, divide with tf.Tensor just like numpy arrays\n",
        "# You can convert a tf.Tensor to a numpy array also\n",
        "\n",
        "for e in example:\n",
        "    print(e)\n",
        "    print(e+1)\n",
        "    print(e*10)\n",
        "    print(e.numpy())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.1, shape=(), dtype=float64)\n",
            "tf.Tensor(1.1, shape=(), dtype=float64)\n",
            "tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "0.1\n",
            "tf.Tensor(23.01, shape=(), dtype=float64)\n",
            "tf.Tensor(24.01, shape=(), dtype=float64)\n",
            "tf.Tensor(230.10000000000002, shape=(), dtype=float64)\n",
            "23.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6xsPI5_9rUv",
        "colab_type": "code",
        "outputId": "1bb82a52-bb53-4977-932d-36ab81126822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "    There is actually no straight-forward way of getting the length of a Dataset type,\n",
        "    you have to find it in a brute force way\n",
        "\"\"\"\n",
        "\n",
        "example = tf.data.Dataset.from_tensor_slices(np.random.randn(100))\n",
        "\n",
        "len_example = [i for i,_ in enumerate(example)][-1] + 1\n",
        "print(f\"Length of dataset is {len_example}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of dataset is 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBz6OzwV7vJx",
        "colab_type": "code",
        "outputId": "d69ea46f-0ea8-4f11-c029-665059474507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "\"\"\"\n",
        "    - Now tf.data.Dataset is very similar to keras ImageDataGenerators but better and faster\n",
        "    - Dataset has many functions which are made to be faster and efficient\n",
        "\"\"\"\n",
        "\n",
        "# Create a dataset with just zeros\n",
        "dataset = tf.data.Dataset.from_tensor_slices([0,0,0,0,0])\n",
        "\n",
        "# Using map function you can add a preprocessing function for the data\n",
        "# You can also use lambda's instead of which can be converted to numpy as followsfunctions\n",
        "\n",
        "\n",
        "def preprocessing_function(tensor):\n",
        "    return tensor+1\n",
        "\n",
        "dataset = dataset.map(preprocessing_function)\n",
        "for element in dataset:\n",
        "    print(element.numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAoQbhE54HxN",
        "colab_type": "code",
        "outputId": "88f4bdc6-1d80-4779-b050-26824ef53559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "\"\"\"\n",
        "    - from_tensor_slices function is made to take input a numpy array or python lists data \n",
        "    and return a dataset\n",
        "    - You give both images and labels at the same time.\n",
        "\"\"\"\n",
        "images, labels = X_train[0], X_train[1]\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    - element_spec is an attribute of dataset that holds a list of data's that we gave\n",
        "    as input to from_tensor_slice and its properties.\n",
        "\"\"\"\n",
        "print(\"Different data's in the dataset are:\")\n",
        "print(f\"The image data is: {dataset.element_spec[0]}\")\n",
        "print(f\"The labesl is: {dataset.element_spec[1]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Different data's in the dataset are:\n",
            "The image data is: TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None)\n",
            "The labesl is: TensorSpec(shape=(1,), dtype=tf.uint8, name=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWbZtBHu3rZJ",
        "colab_type": "text"
      },
      "source": [
        "### To convert our fresh dataset into TFRecords, first we have to convert it to a tf.train.Feature type\n",
        "- a tf.train.Feature is one of these three: ByteList(string and byte type's), FloatList(float32 and float64) and IntList(All kinds of int types)\n",
        "- while seeing the element_spec of our dataset in the above cell, we noticed that both images and labels are of tf.uint8 type so we need to convert our dataset into the int type tf.train.Feature.\n",
        "\n",
        "### What is tf.train.Feature and why do we need it\n",
        "- tf.train.Feature is a way to convert our python data types into something called protocol messages. \n",
        "- These protocol messages are of the form:\n",
        "    ```python\n",
        "    feature_type {\n",
        "        value: value_of_the_data\n",
        "    }\n",
        "    ```\n",
        "- For example\n",
        "    ```python\n",
        "    float32_list {\n",
        "        value: 2.3461    \n",
        "    }\n",
        "\n",
        "    bytes_list {\n",
        "        value: \"Hello Bois\"\n",
        "    }\n",
        "\n",
        "    int64_list {\n",
        "        value: 24\n",
        "    }\n",
        "    ```\n",
        "\n",
        "- More on Protocol Messages ahead.\n",
        "\n",
        "### How to convert our dataset into int type tf.train.Feature?\n",
        "- We need a wrapper function to do this\n",
        "- You can use this [link](https://www.tensorflow.org/tutorials/load_data/tfrecord#tfexample) from tensorflow's documentation  to see the wrapper functions for byte, float and int type.\n",
        "- We are gonna use the int type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIKkjdbb4gxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  \n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy()\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYSwg9QSN44d",
        "colab_type": "code",
        "outputId": "dad010d9-2649-4257-f055-478fdd6de747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "_bytes_feature(b'Hello Halalluaya')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes_list {\n",
              "  value: \"Hello Halalluaya\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT8u9FuhOEUc",
        "colab_type": "code",
        "outputId": "da6f4956-4539-4694-8918-ac102d9104e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "_float_feature(22.32341)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "float_list {\n",
              "  value: 22.323410034179688\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai5B7Toq522Z",
        "colab_type": "code",
        "outputId": "45ddb75a-4cb7-401b-a3a2-3b3857af1634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "_int64_feature(1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int64_list {\n",
              "  value: 1\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHNXF6g5TDZD",
        "colab_type": "text"
      },
      "source": [
        "### How to convert numpy arrays into features\n",
        "- You have to remember that tf.train.Feature can hold only 1-D array and since images have 3 dimensions(width, height, channels), you cannot directly plug it into given wrapper functions and expect them to work\n",
        "- One method to do it is you can convert your numpy array into 1D array and then create tf.train.Feature object with it. However you have to again reshape the array back into its proper shape when extracting\n",
        "- Another method is that you can directy convert your method directly into a string and then plug it in as a ByteList. I dont really how efficient this is, but this seems very hassle free and for smaller datasets, this might not show any problem whatsoever\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7JqhBvHRe3Q",
        "colab_type": "code",
        "outputId": "6668381e-297e-4b8d-850a-c6a974281fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "example_array = np.random.randn(128,32,32,3).tostring()\n",
        "print(example_array[:200])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'~\\xc7\\xa8\\xbb\\xdb\\xfd\\x9d?\\xd6\\x0b\\x9bW-\\xab\\xd4\\xbfd\\x00\\x82\\x14\\xe1:\\xe5?\\x12\\xd8\\x8d2\\xfb\\xc0\\xe3?F\\x04\\x85\\xa3L\\x9a\\x9e\\xbf\\x99X\\xb3\\xff\\x03/\\xe6?\\xbe\\xb8\\x1aPa>\\x9d\\xbfv\\x0e-\\n|\\x12\\xd0\\xbf\\xae#z\\x18\\x85a\\xf3?\\xf5\\xb2\\x968\\xbc\\x1b\\xef\\xbf9{|\\xcdE\\x8b\\xc5\\xbf\\xc1Q\\x1d,\\xd4\\xf4\\x01\\xc07Q\\xe9\\xeb\\x7f\\x1a\\xf0\\xbf\\x93\\n\\x1f\\x9a\\x93\\xd6\\xf4?R\\xfc/*\\x0c7\\xf1\\xbf1;\\x928\\xe3j\\xde\\xbfJ\\x92\\x99\\x87\\xca[\\xe0??&F\\n\\xeb\\xbd\\xd2\\xbf\\xac9{\\xab\\x92\\xec\\xe2\\xbf*\\x0bk#\\xbe\\xba\\xd9\\xbf\\x89\\x8c\\x87\\x848\\xa5\\xeb?\\x91\\x98\\xf5]\\xc9\\x8e\\xf2\\xbf\\x89\\xc6\\x01\\x0c\\xca\\xd8\\xe5?\\xa3$-\\x8fVl\\xe0\\xbf\\xb2W&\\xdb\\xec\\xba\\xb6\\xbf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVTLsw7LWoWj",
        "colab_type": "code",
        "outputId": "159b7285-a2e4-450a-8730-ebd048fc8337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "feature = _bytes_feature(example_array)\n",
        "print(feature.SerializeToString()[:200])\n",
        "#print(feature) wont work as it will exceed the limit of the notebook printing limit"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\n\\x85\\x80\\xc0\\x01\\n\\x80\\x80\\xc0\\x01~\\xc7\\xa8\\xbb\\xdb\\xfd\\x9d?\\xd6\\x0b\\x9bW-\\xab\\xd4\\xbfd\\x00\\x82\\x14\\xe1:\\xe5?\\x12\\xd8\\x8d2\\xfb\\xc0\\xe3?F\\x04\\x85\\xa3L\\x9a\\x9e\\xbf\\x99X\\xb3\\xff\\x03/\\xe6?\\xbe\\xb8\\x1aPa>\\x9d\\xbfv\\x0e-\\n|\\x12\\xd0\\xbf\\xae#z\\x18\\x85a\\xf3?\\xf5\\xb2\\x968\\xbc\\x1b\\xef\\xbf9{|\\xcdE\\x8b\\xc5\\xbf\\xc1Q\\x1d,\\xd4\\xf4\\x01\\xc07Q\\xe9\\xeb\\x7f\\x1a\\xf0\\xbf\\x93\\n\\x1f\\x9a\\x93\\xd6\\xf4?R\\xfc/*\\x0c7\\xf1\\xbf1;\\x928\\xe3j\\xde\\xbfJ\\x92\\x99\\x87\\xca[\\xe0??&F\\n\\xeb\\xbd\\xd2\\xbf\\xac9{\\xab\\x92\\xec\\xe2\\xbf*\\x0bk#\\xbe\\xba\\xd9\\xbf\\x89\\x8c\\x87\\x848\\xa5\\xeb?\\x91\\x98\\xf5]\\xc9\\x8e\\xf2\\xbf\\x89\\xc6\\x01\\x0c\\xca\\xd8\\xe5?\\xa3$-\\x8fVl'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZuvScmPOSwn",
        "colab_type": "text"
      },
      "source": [
        "### Protocol Buffers\n",
        "- Protocol Buffers are a mechanism to serialize data in a structure and efficient way\n",
        "- Serialization of data is a way of converting the data types in python say numpy arrays, keras models, dictionaries, lists and other types into a byte format and the save them in a file so that you can load them later whenever you need them\n",
        "\n",
        "- Protcol buffers are very efficient in the way they serialize data, and are faster than other mechanisms.\n",
        "\n",
        "### tf.train.Example\n",
        "- To use protocol buffers you need to specify protocol messages, these messages are converted into byte stream and then stored into files.\n",
        "- tf.train.Example if a type of message is written as \n",
        " {\"string\":value} mapping.\n",
        "\n",
        "### Creating a tf.train.Example Message\n",
        "- To create a tf.train.Example Message, you need to convert your tf.train.Feature in tf.train.Features.\n",
        "- See below code to convert an image and its label into a tf.Example protocol message.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC8ZZ6k0PK2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_img = np.random.randn(32,32,3)\n",
        "example = original_img.tostring()\n",
        "img_feature = _bytes_feature(example)\n",
        "# Say the label of the image is 5\n",
        "label = _int64_feature(5)\n",
        "feature_dict  = {\n",
        "    'image':img_feature,\n",
        "    'label':label\n",
        "}\n",
        "features = tf.train.Features(feature=feature_dict)\n",
        "tf_example_message = tf.train.Example(features=features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3qZmKTeZAGG",
        "colab_type": "code",
        "outputId": "5761d6e3-2cf5-4979-f4fa-d08104404a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# This is our require byte format that will be written into tfrecord files\n",
        "tf_example_message.SerializeToString()[:50]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'\\n\\xa7\\xc0\\x01\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n\\x93\\xc0\\x01\\n\\x05image\\x12\\x88\\xc0\\x01\\n\\x84\\xc0\\x01\\n\\x80\\xc0\\x01\\xc2g-\\xeem\\xb8\\xea'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fF5lt6Qa5S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proto_bytes = tf_example_message.SerializeToString()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0vJMN6ba4eA",
        "colab_type": "text"
      },
      "source": [
        "### Converting our serialized protocol message back into a numpy array\n",
        "- You have to first define the structure of the original feature dictionary that you created before converting your tf.train.Feature into tf.train.Features.\n",
        "- Create the dictionary with placeholder-like objects called tf.io.FixedLenFeature along with the data-type of each feature in the feature dict.\n",
        "- Then take your protocol message and plug it into tf.io.parse_single_example with your placeholder-like feature dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jLM3KQYcA-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features = \\\n",
        "        {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string),\n",
        "            'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "        }\n",
        "\n",
        "parse_out = tf.io.parse_single_example(features=features, serialized=proto_bytes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxX-XDt8e5mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_out = np.frombuffer(parse_out['image'].numpy())\n",
        "label_out = parse_out['label'].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKsfmlUtgJCQ",
        "colab_type": "code",
        "outputId": "8500b3bb-25a6-49ca-8705-afe292593453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"{label_out}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzvE0PDxfHJ5",
        "colab_type": "code",
        "outputId": "3c40c087-dc1c-4ae8-fa9a-74912214edf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_out == original_img.reshape(-1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ...,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioEDDcPYgpmR",
        "colab_type": "text"
      },
      "source": [
        "### Putting Everything in Place and writing data to tfrecord files\n",
        "- Only thing left to do is to save stuff into tfrecord files and then read them back.\n",
        "- The way to do this is through tf.io.TFRecordWriter\n",
        "- We will now do eveything from scratch and save the CIFAR10 dataset into TFRecord files. \n",
        "- Also I am not sure if we should save the data for all the images in just a single file or not\n",
        "- Make sure you have your shape of image in hand as numpy's tobytes() will flatten out the array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAEEtGs6l2o4",
        "colab_type": "text"
      },
      "source": [
        "##### Writing to a TFRecord File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oePwhDsj6Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "image_shape = X_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EsyBDIekGuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_record_file = 'cifar10.tfrecords'\n",
        "with tf.io.TFRecordWriter(tf_record_file) as writer:\n",
        "    for img, label in zip(X_train[0], X_train[1]):\n",
        "        feature_dict = {\n",
        "            'image': _bytes_feature(img.tobytes()),\n",
        "            'label': _int64_feature(label)\n",
        "        }\n",
        "    \n",
        "        features = tf.train.Features(feature=feature_dict)\n",
        "        tf_example = tf.train.Example(features=features)\n",
        "        protocol_message = tf_example.SerializeToString()\n",
        "\n",
        "        writer.write(protocol_message)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7c1J9n_lkM0",
        "colab_type": "code",
        "outputId": "a9c896be-648a-40e0-ddbe-794ae6f1adb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Yeah! As you can see that huge 150MB file is our entire train dataset for cifar10\n",
        "!du -sh *"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150M\tcifar10.tfrecords\n",
            "55M\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhpXx7ZtlocQ",
        "colab_type": "text"
      },
      "source": [
        "##### Reading from a tfrecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VINPDUdtmDzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_dict = {\n",
        "    'image': tf.io.FixedLenFeature([],tf.string),\n",
        "    'label': tf.io.FixedLenFeature([],tf.string)\n",
        "}\n",
        "\n",
        "dataset = tf.data.TFRecordDataset('cifar10.tfrecords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzLQU10lnM4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "serialized = None\n",
        "for i in dataset.take(1): # take(4) will take the four items from the tfrecord\n",
        "    serialized = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfMC_B9UnQ8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"parse_serialized\n",
        "    - Now we also have to deocode the Image to its numpy form\n",
        "    - To do this create placae-holders and then user the parse_from_single_example function\n",
        "\"\"\"\n",
        "feature_dict = {http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/a-guide/\n",
        "    'image': tf.io.FixedLenFeature([],tf.string),\n",
        "    'label': tf.io.FixedLenFeature([],tf.int64),\n",
        "}\n",
        "parsed_out = tf.io.parse_single_example(serialized=serialized, features=feature_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06eOZsvZHkqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e1fbec51-c897-42d3-9af4-570a3eb9a54d"
      },
      "source": [
        "image = tf.io.decode_raw(parsed_out['image'],out_type=tf.uint8) # Decode the raw bytes\n",
        "image = image.numpy() # Convert it to numpy\n",
        "image = image.reshape(32,32,3) # Reshape the image back to its original size\n",
        "plt.imshow(image) # Plot the image\n",
        "print(parsed_out['label'])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tVjBRWZJGxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    - Lets write functions to do this automatically\n",
        "\"\"\"\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  \n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy()\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def convert_np_to_tf_example(image, label):\n",
        "    feature_dict = {\n",
        "        'image': _bytes_feature(image.tostring()),\n",
        "        'label': _int64_feature(label),\n",
        "    }\n",
        "\n",
        "    features = tf.train.Features(feature=feature_dict)\n",
        "    tf_example = tf.train.Example(features=features)\n",
        "    protocol_message = tf_example.SerializeToString()\n",
        "\n",
        "    return protocol_message\n",
        "\n",
        "def convert_proto_message_to_np(protocol_message):\n",
        "    feature_dict = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "    }\n",
        "\n",
        "    parsed_out = tf.io.parse_single_example(serialized=protocol_message,\n",
        "                                            features=feature_dict)\n",
        "    \n",
        "    image = tf.io.decode_raw(parsed_out['image'], out_type=tf.uint8)\n",
        "    label = parsed_out['label']\n",
        "\n",
        "    return (image,label)\n",
        "    \n",
        "def reshape_img(X, img_shape):\n",
        "    img = X[0].numpy()\n",
        "    label = X[1]\n",
        "    img = img.reshape(img_shape)\n",
        "    img_tensor = tf.convert_to_tensor(img)\n",
        "\n",
        "    return (img_tensor, label)\n",
        "    \n",
        "\n",
        "def convert_np_to_tfrecords(images, labels, \n",
        "                            batch_size=128,filename=None):\n",
        "    \"\"\"        for img in (images,labels):\n",
        "\n",
        "        Converts a numpy array into TFReocrds\n",
        "    \"\"\"\n",
        "    assert images.shape[0] == labels.shape[0], \" Number of Images is not equal to number of labels\"\n",
        "\n",
        "    channels = images.shape[-1]\n",
        "    width = images.shape[-2]\n",
        "    height = images.shape[-3]\n",
        "\n",
        "    img_shape = (height, width, channels)\n",
        "    if filename == None:\n",
        "        filename = 'dataset.tfrecords'\n",
        "    with tf.io.TFRecordWriter(filename) as writer:\n",
        "        for img,label in zip(images,labels):\n",
        "            protocol_message = convert_np_to_tf_example(img,label)\n",
        "\n",
        "            writer.write(protocol_message)\n",
        "        \n",
        "    dataset = tf.data.TFRecordDataset(filename)\n",
        "    dataset = dataset.map(convert_proto_message_to_np)\n",
        "    dataset = dataset.map(lambda x, y: (tf.reshape(x,img_shape), y))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6zSlsQePWaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "46354299-26c8-470f-f88d-2395bb81c15a"
      },
      "source": [
        "dataset = convert_np_to_tfrecords(X_train[0],X_train[1])\n",
        "for d in dataset.take(1):\n",
        "    plt.imshow(d[0].numpy()[0])\n",
        "    print(d[1][0])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Hp5b0CS2lG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ebd8727-5326-45e0-ff52-2e362bc6f14a"
      },
      "source": [
        "k(2,3)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MjIAgsSS5YS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}