{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet18.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0L78bY7U--T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "37a46159-52c0-4e4b-c937-8c1b6a6c4f17"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGMS_351VE_2",
        "colab_type": "text"
      },
      "source": [
        "# Build the outermost model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU9E-MuiWQgi",
        "colab_type": "text"
      },
      "source": [
        "### A BatchNorm->Relu Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rUZWn4MWWCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _br():\n",
        "  def f(inputs):\n",
        "    bn = tf.keras.layers.BatchNormalization(axis=-1)(inputs)\n",
        "    relu = tf.keras.layers.Activation('relu')(bn)\n",
        "\n",
        "    return relu\n",
        "\n",
        "  return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuy2Oi4-T3fp",
        "colab_type": "text"
      },
      "source": [
        "### A conv->bn->relu Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCDhfY_yT8Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _cbr(filters,kernel_size=3,strides=1):\n",
        "   \n",
        "  def f(inputs):\n",
        "    conv2d = tf.keras.layers.Conv2D(filters=filters,kernel_size=kernel_size,\n",
        "                                    strides=strides,padding='same',\n",
        "                                    use_bias=False, kernel_initializer='he_normal',\n",
        "                                    #kernel_regularizer=tf.keras.regularizers.l2(5e-4)\n",
        "                                    )(inputs)\n",
        "  \n",
        "    br = _br()(conv2d)\n",
        "\n",
        "    return br\n",
        "  return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWYnLuBRXYiU",
        "colab_type": "text"
      },
      "source": [
        "### Building a block according from the arctitecture given in how to train your resnet: baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qH1z5zgXjae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _block(filters,strides=1,first=False, scaledown=True):\n",
        "  def f(inputs):\n",
        "    x = inputs\n",
        "    identity = x\n",
        "    if(first == False):\n",
        "      x = _br()(x)\n",
        "    \n",
        "    if(strides == 2 or scaledown==False):\n",
        "      identity = tf.keras.layers.Conv2D(filters=filters,kernel_size=1,strides=strides,\n",
        "                                        use_bias=False,kernel_initializer='he_normal',\n",
        "                                        #kernel_regularizer=tf.keras.regularizers.l2(5e-4)\n",
        "                                         )(identity)\n",
        "      identity = tf.keras.layers.BatchNormalization(axis=-1)(identity)\n",
        "      #identity = _cbr(filters,kernel_size=1,strides=strides)(identity)\n",
        "    \n",
        "    # Create a branch as follows: conv1->bn->relu->conv2 and add x + conv2\n",
        "    x = _cbr(filters,strides=strides)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=filters,kernel_size=3,\n",
        "                               strides=1,padding='same',use_bias=False,\n",
        "                               kernel_initializer='he_normal',\n",
        "                               #kernel_regularizer=tf.keras.regularizers.l2(5e-4),\n",
        "                               )(x)\n",
        "    \n",
        "    # Now addition operation\n",
        "    x = tf.keras.layers.add([identity,x])\n",
        "\n",
        "    return x\n",
        "  return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiiycdX-wKH8",
        "colab_type": "text"
      },
      "source": [
        "### This is the block mention in the Identity importance Paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EQQoFfzwO-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _res_block(filters,strides=1):\n",
        "\n",
        "  def f(inputs):\n",
        "    identity = inputs\n",
        "    x = inputs\n",
        "    if strides==2:\n",
        "      #identity = tf.keras.layers.Conv2D(filters,kernel_size=1,strides=2,\n",
        "      #                                  using_bias=False,kernel_initializer=False)(identity)\n",
        "      identity = _cbr(filters,kernel_size=1,strides=2)(identity)\n",
        "\n",
        "    x = _cbr(filters,strides=strides)(x)\n",
        "    x = _cbr(filters,strides=1)(x)\n",
        "\n",
        "    x = tf.keras.layers.add([identity,x])\n",
        "\n",
        "    return x\n",
        "  return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkI3rSz1bMLz",
        "colab_type": "text"
      },
      "source": [
        "### Build a layer from the resnet 18 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guvEnDZxbQm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _layer(filters,first=False,scaledown=True):\n",
        "\n",
        "  def f(inputs):\n",
        "    # Create two blocks \n",
        "    strides = 2\n",
        "    if(scaledown == False):\n",
        "      strides=1\n",
        "    block_1 = _block(filters=filters,strides=strides, scaledown=scaledown)(inputs)\n",
        "    block_2 = _block(filters=filters,strides=1, scaledown=scaledown)(block_1)\n",
        "\n",
        "    return block_2\n",
        "  \n",
        "  return f\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FimgPgX5cNiX",
        "colab_type": "text"
      },
      "source": [
        "### Now build the complete Resnet18 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMpAelWkTX2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Resnet18():\n",
        "  inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "  conv_7x7 = tf.keras.layers.Conv2D(filters=64,kernel_size=7,strides=1, padding='same')(inputs)\n",
        "  layer_1 = _layer(filters=64,first=True,scaledown=False)(conv_7x7)\n",
        "  layer_2 = _layer(filters=128)(layer_1)\n",
        "  # The scaledown exists beacuse, the size of input image is reducing way too fast\n",
        "  layer_3 = _layer(filters=256, scaledown=True)(layer_2)\n",
        "  layer_4 = _layer(filters=512, scaledown=False)(layer_3)\n",
        "  avg = tf.keras.layers.GlobalAveragePooling2D()(layer_4)\n",
        "  #conv_8x8 = tf.keras.layers.Conv2D(10,8,1)(layer_4)\n",
        "  #flatten = tf.keras.layers.Flatten()(conv_8x8)\n",
        "  outputs = tf.keras.layers.Dense(10,activation='softmax')(avg)\n",
        "  \n",
        "  model = tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR60mI0GTyEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d29e1ae-d818-412d-d8a4-02075fea868e"
      },
      "source": [
        "# Now test it on some random image\n",
        "img = np.random.uniform(0,1,size=(1,32,32,3)).astype('float32')\n",
        "print(img.shape)\n",
        "model = Resnet18()\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 32, 32, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36864       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   4096        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 64)   36864       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36864       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 64)   4096        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36864       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 128)  73728       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 128)  8192        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147456      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 128)  0           batch_normalization_7[0][0]      \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 128)  147456      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 128)  147456      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 128)  0           add_2[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 256)    294912      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 256)    32768       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 256)    589824      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 256)    0           batch_normalization_12[0][0]     \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 256)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 256)    589824      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 256)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 256)    589824      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 256)    0           add_4[0][0]                      \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 256)    1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 256)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 512)    1179648     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 512)    2048        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 512)    131072      add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 512)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 512)    2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 512)    2359296     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 512)    0           batch_normalization_17[0][0]     \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 512)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 512)    2359296     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 512)    2048        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 512)    262144      add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 512)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 512)    2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 512)    2359296     activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 512)    0           batch_normalization_20[0][0]     \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 512)          0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           5130        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 11,462,154\n",
            "Trainable params: 11,452,298\n",
            "Non-trainable params: 9,856\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0sJjobte6gQ",
        "colab_type": "text"
      },
      "source": [
        "# Training the Resnet 18 for CIFAR 10 for 300 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F5bAPdve9lW",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data set\n",
        "Augement the dataset as the input type must be uint8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmms1wgKe_u8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "(X_train,y_train), (X_test,y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "mean,std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
        "#mean, std = X_train.mean(axis=(0,1,2)), X_train.std(axis=(0,1,2))\n",
        "\n",
        "X_train = (X_train-mean)/std\n",
        "X_test = (X_test - mean)/std\n",
        "\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "# Pad 4px and Crop to 32,32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Jg7qKnJ0Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_erasing(img):\n",
        "  global mean\n",
        "  r = np.random.randint(0,2)\n",
        "  if(r == 0):\n",
        "    return img\n",
        "  h = np.random.randint(img.shape[0]//3,img.shape[0]//2)\n",
        "  w = np.random.randint(img.shape[1]//3,img.shape[1]//2)\n",
        "\n",
        "  x = np.random.randint(0,img.shape[0]//2)\n",
        "  y = np.random.randint(0,img.shape[1]//2)\n",
        "\n",
        "  img[x:x+h,y:y+h,:] = mean\n",
        "\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anfq2h6J33g7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def pad_and_crop(img):\n",
        "  if(np.random.randint(0,2) == 0):\n",
        "    return img\n",
        "  img =  np.pad(img,((4,4),(4,4),(0,0)),mode='constant')\n",
        "  x,y = np.random.randint(0,4), np.random.randint(0,4)\n",
        "  img = img[x:x+32,y:y+32,:]\n",
        "  return img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm4_AQ3QCmr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def horizontal_flip(img):\n",
        "  if(np.random.randint(0,2) == 0):\n",
        "    return img\n",
        "  return np.flip(img,[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMZtD_8EDy4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_aug(img):\n",
        "  img = pad_and_crop(img)\n",
        "  img = random_erasing(img)\n",
        "  #img = horizontal_flip(img)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P654i8svGtCX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10056b5f-81a3-4ca3-d4e1-ff1104862ed7"
      },
      "source": [
        "## Image data generator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "#    preprocessing_function=pad_and_crop_ra,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "#\n",
        "for i in range(len(X_train)):\n",
        "  print(f\"\\rAugmention Image:{i}/{len(X_train)}\", end=\" \")\n",
        "  X_train[i] = data_aug(X_train[i])\n",
        "train_data = train_datagen.flow(X_train,y_train,batch_size=BATCH_SIZE,)\n",
        "test_data = ImageDataGenerator().flow(X_test,y_test,batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmention Image:49999/50000 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihLIWgnIHIgj",
        "colab_type": "text"
      },
      "source": [
        "### Using Cyclic LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9uI0GUFHvMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "be8cd06d-dfef-4a84-8294-e55c4c6f80aa"
      },
      "source": [
        "!rm -rf DLlib\n",
        "!git clone \"https://github.com/RaghavendraGaleppa/DLlib\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DLlib'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/118)\u001b[K\rremote: Counting objects:   1% (2/118)\u001b[K\rremote: Counting objects:   2% (3/118)\u001b[K\rremote: Counting objects:   3% (4/118)\u001b[K\rremote: Counting objects:   4% (5/118)\u001b[K\rremote: Counting objects:   5% (6/118)\u001b[K\rremote: Counting objects:   6% (8/118)\u001b[K\rremote: Counting objects:   7% (9/118)\u001b[K\rremote: Counting objects:   8% (10/118)\u001b[K\rremote: Counting objects:   9% (11/118)\u001b[K\rremote: Counting objects:  10% (12/118)\u001b[K\rremote: Counting objects:  11% (13/118)\u001b[K\rremote: Counting objects:  12% (15/118)\u001b[K\rremote: Counting objects:  13% (16/118)\u001b[K\rremote: Counting objects:  14% (17/118)\u001b[K\rremote: Counting objects:  15% (18/118)\u001b[K\rremote: Counting objects:  16% (19/118)\u001b[K\rremote: Counting objects:  17% (21/118)\u001b[K\rremote: Counting objects:  18% (22/118)\u001b[K\rremote: Counting objects:  19% (23/118)\u001b[K\rremote: Counting objects:  20% (24/118)\u001b[K\rremote: Counting objects:  21% (25/118)\u001b[K\rremote: Counting objects:  22% (26/118)\u001b[K\rremote: Counting objects:  23% (28/118)\u001b[K\rremote: Counting objects:  24% (29/118)\u001b[K\rremote: Counting objects:  25% (30/118)\u001b[K\rremote: Counting objects:  26% (31/118)\u001b[K\rremote: Counting objects:  27% (32/118)\u001b[K\rremote: Counting objects:  28% (34/118)\u001b[K\rremote: Counting objects:  29% (35/118)\u001b[K\rremote: Counting objects:  30% (36/118)\u001b[K\rremote: Counting objects:  31% (37/118)\u001b[K\rremote: Counting objects:  32% (38/118)\u001b[K\rremote: Counting objects:  33% (39/118)\u001b[K\rremote: Counting objects:  34% (41/118)\u001b[K\rremote: Counting objects:  35% (42/118)\u001b[K\rremote: Counting objects:  36% (43/118)\u001b[K\rremote: Counting objects:  37% (44/118)\u001b[K\rremote: Counting objects:  38% (45/118)\u001b[K\rremote: Counting objects:  39% (47/118)\u001b[K\rremote: Counting objects:  40% (48/118)\u001b[K\rremote: Counting objects:  41% (49/118)\u001b[K\rremote: Counting objects:  42% (50/118)\u001b[K\rremote: Counting objects:  43% (51/118)\u001b[K\rremote: Counting objects:  44% (52/118)\u001b[K\rremote: Counting objects:  45% (54/118)\u001b[K\rremote: Counting objects:  46% (55/118)\u001b[K\rremote: Counting objects:  47% (56/118)\u001b[K\rremote: Counting objects:  48% (57/118)\u001b[K\rremote: Counting objects:  49% (58/118)\u001b[K\rremote: Counting objects:  50% (59/118)\u001b[K\rremote: Counting objects:  51% (61/118)\u001b[K\rremote: Counting objects:  52% (62/118)\u001b[K\rremote: Counting objects:  53% (63/118)\u001b[K\rremote: Counting objects:  54% (64/118)\u001b[K\rremote: Counting objects:  55% (65/118)\u001b[K\rremote: Counting objects:  56% (67/118)\u001b[K\rremote: Counting objects:  57% (68/118)\u001b[K\rremote: Counting objects:  58% (69/118)\u001b[K\rremote: Counting objects:  59% (70/118)\u001b[K\rremote: Counting objects:  60% (71/118)\u001b[K\rremote: Counting objects:  61% (72/118)\u001b[K\rremote: Counting objects:  62% (74/118)\u001b[K\rremote: Counting objects:  63% (75/118)\u001b[K\rremote: Counting objects:  64% (76/118)\u001b[K\rremote: Counting objects:  65% (77/118)\u001b[K\rremote: Counting objects:  66% (78/118)\u001b[K\rremote: Counting objects:  67% (80/118)\u001b[K\rremote: Counting objects:  68% (81/118)\u001b[K\rremote: Counting objects:  69% (82/118)\u001b[K\rremote: Counting objects:  70% (83/118)\u001b[K\rremote: Counting objects:  71% (84/118)\u001b[K\rremote: Counting objects:  72% (85/118)\u001b[K\rremote: Counting objects:  73% (87/118)\u001b[K\rremote: Counting objects:  74% (88/118)\u001b[K\rremote: Counting objects:  75% (89/118)\u001b[K\rremote: Counting objects:  76% (90/118)\u001b[K\rremote: Counting objects:  77% (91/118)\u001b[K\rremote: Counting objects:  78% (93/118)\u001b[K\rremote: Counting objects:  79% (94/118)\u001b[K\rremote: Counting objects:  80% (95/118)\u001b[K\rremote: Counting objects:  81% (96/118)\u001b[K\rremote: Counting objects:  82% (97/118)\u001b[K\rremote: Counting objects:  83% (98/118)\u001b[K\rremote: Counting objects:  84% (100/118)\u001b[K\rremote: Counting objects:  85% (101/118)\u001b[K\rremote: Counting objects:  86% (102/118)\u001b[K\rremote: Counting objects:  87% (103/118)\u001b[K\rremote: Counting objects:  88% (104/118)\u001b[K\rremote: Counting objects:  89% (106/118)\u001b[K\rremote: Counting objects:  90% (107/118)\u001b[K\rremote: Counting objects:  91% (108/118)\u001b[K\rremote: Counting objects:  92% (109/118)\u001b[K\rremote: Counting objects:  93% (110/118)\u001b[K\rremote: Counting objects:  94% (111/118)\u001b[K\rremote: Counting objects:  95% (113/118)\u001b[K\rremote: Counting objects:  96% (114/118)\u001b[K\rremote: Counting objects:  97% (115/118)\u001b[K\rremote: Counting objects:  98% (116/118)\u001b[K\rremote: Counting objects:  99% (117/118)\u001b[K\rremote: Counting objects: 100% (118/118)\u001b[K\rremote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/81)\u001b[K\rremote: Compressing objects:   2% (2/81)\u001b[K\rremote: Compressing objects:   3% (3/81)\u001b[K\rremote: Compressing objects:   4% (4/81)\u001b[K\rremote: Compressing objects:   6% (5/81)\u001b[K\rremote: Compressing objects:   7% (6/81)\u001b[K\rremote: Compressing objects:   8% (7/81)\u001b[K\rremote: Compressing objects:   9% (8/81)\u001b[K\rremote: Compressing objects:  11% (9/81)\u001b[K\rremote: Compressing objects:  12% (10/81)\u001b[K\rremote: Compressing objects:  13% (11/81)\u001b[K\rremote: Compressing objects:  14% (12/81)\u001b[K\rremote: Compressing objects:  16% (13/81)\u001b[K\rremote: Compressing objects:  17% (14/81)\u001b[K\rremote: Compressing objects:  18% (15/81)\u001b[K\rremote: Compressing objects:  19% (16/81)\u001b[K\rremote: Compressing objects:  20% (17/81)\u001b[K\rremote: Compressing objects:  22% (18/81)\u001b[K\rremote: Compressing objects:  23% (19/81)\u001b[K\rremote: Compressing objects:  24% (20/81)\u001b[K\rremote: Compressing objects:  25% (21/81)\u001b[K\rremote: Compressing objects:  27% (22/81)\u001b[K\rremote: Compressing objects:  28% (23/81)\u001b[K\rremote: Compressing objects:  29% (24/81)\u001b[K\rremote: Compressing objects:  30% (25/81)\u001b[K\rremote: Compressing objects:  32% (26/81)\u001b[K\rremote: Compressing objects:  33% (27/81)\u001b[K\rremote: Compressing objects:  34% (28/81)\u001b[K\rremote: Compressing objects:  35% (29/81)\u001b[K\rremote: Compressing objects:  37% (30/81)\u001b[K\rremote: Compressing objects:  38% (31/81)\u001b[K\rremote: Compressing objects:  39% (32/81)\u001b[K\rremote: Compressing objects:  40% (33/81)\u001b[K\rremote: Compressing objects:  41% (34/81)\u001b[K\rremote: Compressing objects:  43% (35/81)\u001b[K\rremote: Compressing objects:  44% (36/81)\u001b[K\rremote: Compressing objects:  45% (37/81)\u001b[K\rremote: Compressing objects:  46% (38/81)\u001b[K\rremote: Compressing objects:  48% (39/81)\u001b[K\rremote: Compressing objects:  49% (40/81)\u001b[K\rremote: Compressing objects:  50% (41/81)\u001b[K\rremote: Compressing objects:  51% (42/81)\u001b[K\rremote: Compressing objects:  53% (43/81)\u001b[K\rremote: Compressing objects:  54% (44/81)\u001b[K\rremote: Compressing objects:  55% (45/81)\u001b[K\rremote: Compressing objects:  56% (46/81)\u001b[K\rremote: Compressing objects:  58% (47/81)\u001b[K\rremote: Compressing objects:  59% (48/81)\u001b[K\rremote: Compressing objects:  60% (49/81)\u001b[K\rremote: Compressing objects:  61% (50/81)\u001b[K\rremote: Compressing objects:  62% (51/81)\u001b[K\rremote: Compressing objects:  64% (52/81)\u001b[K\rremote: Compressing objects:  65% (53/81)\u001b[K\rremote: Compressing objects:  66% (54/81)\u001b[K\rremote: Compressing objects:  67% (55/81)\u001b[K\rremote: Compressing objects:  69% (56/81)\u001b[K\rremote: Compressing objects:  70% (57/81)\u001b[K\rremote: Compressing objects:  71% (58/81)\u001b[K\rremote: Compressing objects:  72% (59/81)\u001b[K\rremote: Compressing objects:  74% (60/81)\u001b[K\rremote: Compressing objects:  75% (61/81)\u001b[K\rremote: Compressing objects:  76% (62/81)\u001b[K\rremote: Compressing objects:  77% (63/81)\u001b[K\rremote: Compressing objects:  79% (64/81)\u001b[K\rremote: Compressing objects:  80% (65/81)\u001b[K\rremote: Compressing objects:  81% (66/81)\u001b[K\rremote: Compressing objects:  82% (67/81)\u001b[K\rremote: Compressing objects:  83% (68/81)\u001b[K\rremote: Compressing objects:  85% (69/81)\u001b[K\rremote: Compressing objects:  86% (70/81)\u001b[K\rremote: Compressing objects:  87% (71/81)\u001b[K\rremote: Compressing objects:  88% (72/81)\u001b[K\rremote: Compressing objects:  90% (73/81)\u001b[K\rremote: Compressing objects:  91% (74/81)\u001b[K\rremote: Compressing objects:  92% (75/81)\u001b[K\rremote: Compressing objects:  93% (76/81)\u001b[K\rremote: Compressing objects:  95% (77/81)\u001b[K\rremote: Compressing objects:  96% (78/81)\u001b[K\rremote: Compressing objects:  97% (79/81)\u001b[K\rremote: Compressing objects:  98% (80/81)\u001b[K\rremote: Compressing objects: 100% (81/81)\u001b[K\rremote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 118 (delta 51), reused 96 (delta 31), pack-reused 0\u001b[K\n",
            "Receiving objects:   0% (1/118)   \rReceiving objects:   1% (2/118)   \rReceiving objects:   2% (3/118)   \rReceiving objects:   3% (4/118)   \rReceiving objects:   4% (5/118)   \rReceiving objects:   5% (6/118)   \rReceiving objects:   6% (8/118)   \rReceiving objects:   7% (9/118)   \rReceiving objects:   8% (10/118)   \rReceiving objects:   9% (11/118)   \rReceiving objects:  10% (12/118)   \rReceiving objects:  11% (13/118)   \rReceiving objects:  12% (15/118)   \rReceiving objects:  13% (16/118)   \rReceiving objects:  14% (17/118)   \rReceiving objects:  15% (18/118)   \rReceiving objects:  16% (19/118)   \rReceiving objects:  17% (21/118)   \rReceiving objects:  18% (22/118)   \rReceiving objects:  19% (23/118)   \rReceiving objects:  20% (24/118)   \rReceiving objects:  21% (25/118)   \rReceiving objects:  22% (26/118)   \rReceiving objects:  23% (28/118)   \rReceiving objects:  24% (29/118)   \rReceiving objects:  25% (30/118)   \rReceiving objects:  26% (31/118)   \rReceiving objects:  27% (32/118)   \rReceiving objects:  28% (34/118)   \rReceiving objects:  29% (35/118)   \rReceiving objects:  30% (36/118)   \rReceiving objects:  31% (37/118)   \rReceiving objects:  32% (38/118)   \rReceiving objects:  33% (39/118)   \rReceiving objects:  34% (41/118)   \rReceiving objects:  35% (42/118)   \rReceiving objects:  36% (43/118)   \rReceiving objects:  37% (44/118)   \rReceiving objects:  38% (45/118)   \rReceiving objects:  39% (47/118)   \rReceiving objects:  40% (48/118)   \rReceiving objects:  41% (49/118)   \rReceiving objects:  42% (50/118)   \rReceiving objects:  43% (51/118)   \rReceiving objects:  44% (52/118)   \rReceiving objects:  45% (54/118)   \rReceiving objects:  46% (55/118)   \rReceiving objects:  47% (56/118)   \rReceiving objects:  48% (57/118)   \rReceiving objects:  49% (58/118)   \rReceiving objects:  50% (59/118)   \rReceiving objects:  51% (61/118)   \rReceiving objects:  52% (62/118)   \rReceiving objects:  53% (63/118)   \rReceiving objects:  54% (64/118)   \rReceiving objects:  55% (65/118)   \rReceiving objects:  56% (67/118)   \rReceiving objects:  57% (68/118)   \rReceiving objects:  58% (69/118)   \rReceiving objects:  59% (70/118)   \rReceiving objects:  60% (71/118)   \rReceiving objects:  61% (72/118)   \rReceiving objects:  62% (74/118)   \rReceiving objects:  63% (75/118)   \rReceiving objects:  64% (76/118)   \rReceiving objects:  65% (77/118)   \rReceiving objects:  66% (78/118)   \rReceiving objects:  67% (80/118)   \rReceiving objects:  68% (81/118)   \rReceiving objects:  69% (82/118)   \rReceiving objects:  70% (83/118)   \rReceiving objects:  71% (84/118)   \rReceiving objects:  72% (85/118)   \rReceiving objects:  73% (87/118)   \rReceiving objects:  74% (88/118)   \rReceiving objects:  75% (89/118)   \rReceiving objects:  76% (90/118)   \rReceiving objects:  77% (91/118)   \rReceiving objects:  78% (93/118)   \rReceiving objects:  79% (94/118)   \rReceiving objects:  80% (95/118)   \rReceiving objects:  81% (96/118)   \rReceiving objects:  82% (97/118)   \rReceiving objects:  83% (98/118)   \rReceiving objects:  84% (100/118)   \rReceiving objects:  85% (101/118)   \rReceiving objects:  86% (102/118)   \rReceiving objects:  87% (103/118)   \rReceiving objects:  88% (104/118)   \rReceiving objects:  89% (106/118)   \rReceiving objects:  90% (107/118)   \rReceiving objects:  91% (108/118)   \rReceiving objects:  92% (109/118)   \rReceiving objects:  93% (110/118)   \rReceiving objects:  94% (111/118)   \rReceiving objects:  95% (113/118)   \rReceiving objects:  96% (114/118)   \rReceiving objects:  97% (115/118)   \rReceiving objects:  98% (116/118)   \rReceiving objects:  99% (117/118)   \rReceiving objects: 100% (118/118)   \rReceiving objects: 100% (118/118), 20.79 KiB | 10.39 MiB/s, done.\n",
            "Resolving deltas:   0% (0/51)   \rResolving deltas:   9% (5/51)   \rResolving deltas:  17% (9/51)   \rResolving deltas:  23% (12/51)   \rResolving deltas:  25% (13/51)   \rResolving deltas:  27% (14/51)   \rResolving deltas:  33% (17/51)   \rResolving deltas:  35% (18/51)   \rResolving deltas:  37% (19/51)   \rResolving deltas:  58% (30/51)   \rResolving deltas:  74% (38/51)   \rResolving deltas:  80% (41/51)   \rResolving deltas:  86% (44/51)   \rResolving deltas:  90% (46/51)   \rResolving deltas: 100% (51/51)   \rResolving deltas: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rlpOxxrHNFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import DLlib as d\n",
        "from tensorflow.keras.callbacks import *\n",
        "step_size = 10\n",
        "#iter_size = 100\n",
        "iter_size = len(X_train)//BATCH_SIZE\n",
        "epochs = 300\n",
        "\n",
        "clr_triangular = d.utils.CyclicLR(base_lr=0.004,max_lr=0.1,step_size=2000)\n",
        "sgdr = d.utils.SGDRestart(base_lr=0.004,max_lr=0.01,step_size=200)\n",
        "cym = d.utils.CyclicMomentum(base_lr=0.9, max_lr=0.85, step_size=2000)\n",
        "\n",
        "modelCheckpoint1 = tf.keras.callbacks.ModelCheckpoint('every_50',save_freq=390*50)\n",
        "modelCheckpoint2 = tf.keras.callbacks.ModelCheckpoint('best_model',monitor='val_acc', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiCKjD4t2TVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_loss(model,weight_decay):\n",
        "  def custom_loss(y, y_pred):\n",
        "    ''' A custom loss function to include weight decay '''\n",
        "    loss = tf.keras.losses.categorical_crossentropy(y, y_pred)\n",
        "    layers = [l for l in model.layers if type(l) == tf.keras.layers.Conv2D]\n",
        "    total_loss = 0.0\n",
        "    for l in layers:\n",
        "      total_loss += tf.nn.l2_loss(l.trainable_weights[0])\n",
        "    \n",
        "    return loss + total_loss*weight_decay\n",
        "  return custom_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By6EMy7RfzwE",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUGwjPvWgH6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "72c5b9e4-bf25-4e6b-fe9a-255864ad29d4"
      },
      "source": [
        "model = Resnet18()\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.01,nesterov=True,momentum=0.9,decay=0)\n",
        "model.compile(loss=weighted_loss(model, 5e-4),\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit_generator(train_data,steps_per_epoch=len(X_train)/BATCH_SIZE,\n",
        "        epochs=epochs,validation_data=test_data,\n",
        "        validation_steps=len(X_test)/BATCH_SIZE,\n",
        "        callbacks=[clr_triangular]\n",
        ")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "390/390 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.9372Epoch 1/300\n",
            "391/390 [==============================] - 130s 332ms/step - loss: 0.6113 - acc: 0.9372 - val_loss: 0.9712 - val_acc: 0.8433\n",
            "Epoch 30/300\n",
            "390/390 [============================>.] - ETA: 0s - loss: 0.4991 - acc: 0.9676Epoch 1/300\n",
            "391/390 [==============================] - 130s 332ms/step - loss: 0.4990 - acc: 0.9677 - val_loss: 0.8200 - val_acc: 0.8887\n",
            "Epoch 31/300\n",
            "390/390 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.9882Epoch 1/300\n",
            "391/390 [==============================] - 130s 332ms/step - loss: 0.4244 - acc: 0.9882 - val_loss: 0.7693 - val_acc: 0.9057\n",
            "Epoch 32/300\n",
            " 88/390 [=====>........................] - ETA: 1:35 - loss: 0.4001 - acc: 0.9942"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2041d9786a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclr_triangular\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP8as6sy3CMy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Writing custom training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1fWy6YLO3CD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLx-llwc3Znq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.semilogx(clr_triangular.history['lr'], clr_triangular.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKRmW5r2t673",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.semilogx(clr_triangular.history['lr'], clr_triangular.history['loss'])\n",
        "plt.semilogx(clr_triangular.history['lr'], clr_triangular.history['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHoVRC3w1Miy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr_triangular.plot_lr_loss(loss_threshold=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4ZlaJ9WpYlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_twin(lr,loss,acc):\n",
        "  fig, ax1 = plt.subplots(figsize=(5,5))\n",
        "  ax1.set_xlabel('lr', fontsize=16)\n",
        "  ax1.set_ylabel('loss', fontsize=16)\n",
        "  ax1.semilogx(lr,loss,c='r', label='loss')\n",
        "  ax1.legend()\n",
        "\n",
        "  ax2 = ax1.twinx()\n",
        "  ax2.set_ylabel('acc', fontsize=16)\n",
        "  ax2.semilogx(lr,acc,c='b',label='acc')\n",
        "  ax2.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxjM6kTARPPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_twin(clr_triangular.history['lr'],\n",
        "          clr_triangular.history['loss'],\n",
        "          clr_triangular.history['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zffUNg8TRZc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}